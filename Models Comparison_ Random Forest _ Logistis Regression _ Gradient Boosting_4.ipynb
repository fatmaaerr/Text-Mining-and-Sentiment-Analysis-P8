{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eac04674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f99af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import contractions\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5991b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU, Bidirectional\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "726bf24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweet-preprocessor in c:\\users\\fatma.er\\anaconda3\\lib\\site-packages (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tweet-preprocessor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f6d497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import emoji\n",
    "import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "\n",
    "#sklearn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#from keras.layers.recurrent import LSTM, GRU,SimpleRNN \n",
    "from keras.layers import Dense, Embedding, LSTM, GRU, Bidirectional,SimpleRNN\n",
    "\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "#from keras.layers.embeddings import Embedding\n",
    "\n",
    "#importing  libraries\n",
    "#Keras\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import regularizers, layers\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model, model_from_json\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#import transformers\n",
    "#from transformers import TFAutoModel, AutoTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "#from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f08626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44d49cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb641303",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save clean_df to csv file\n",
    "#clean_df.to_csv('clean_df.csv', index=False)\n",
    "Tweet_Dataset_model = pd.read_csv('Model_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7388edde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>content_token</th>\n",
       "      <th>synonym</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>clean_tweet_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.956968e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>['want', 'trade', 'someone', 'houston', 'ticke...</td>\n",
       "      <td>[['privation', 'want', 'deprivation', 'needine...</td>\n",
       "      <td>want trade someone houston ticket one</td>\n",
       "      <td>['want', 'trade', 'someone', 'houston', 'ticke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.956969e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>cant fall asleep</td>\n",
       "      <td>['cant', 'fall', 'asleep']</td>\n",
       "      <td>[['buzzword', 'cant', 'bank', 'cant', 'camber'...</td>\n",
       "      <td>cant fall asleep</td>\n",
       "      <td>['cant', 'fall', 'asleep']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.956972e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>No Topic Maps talks at the Balisage Markup Con...</td>\n",
       "      <td>['topic', 'map', 'talk', 'balisage', 'markup',...</td>\n",
       "      <td>[['subject', 'topic', 'theme', 'topic', 'subje...</td>\n",
       "      <td>topic map talk balisage markup conference prog...</td>\n",
       "      <td>['topic', 'map', 'talk', 'balisage', 'markup',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.956975e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@cynthia_123 i cant sleep</td>\n",
       "      <td>['cant', 'sleep']</td>\n",
       "      <td>[['buzzword', 'cant', 'bank', 'cant', 'camber'...</td>\n",
       "      <td>cant sleep</td>\n",
       "      <td>['cant', 'sleep']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.956976e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I missed the bl***y bus!!!!!!!!</td>\n",
       "      <td>['missed', 'bly', 'bus']</td>\n",
       "      <td>[['miss', 'lose', 'miss', 'miss', 'neglect', '...</td>\n",
       "      <td>missed bl bus</td>\n",
       "      <td>['missed', 'bl', 'bus']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id sentiment                                            content  \\\n",
       "0  1.956968e+09   neutral  @dannycastillo We want to trade with someone w...   \n",
       "1  1.956969e+09   neutral                                   cant fall asleep   \n",
       "2  1.956972e+09   neutral  No Topic Maps talks at the Balisage Markup Con...   \n",
       "3  1.956975e+09   neutral                          @cynthia_123 i cant sleep   \n",
       "4  1.956976e+09   neutral                    I missed the bl***y bus!!!!!!!!   \n",
       "\n",
       "                                       content_token  \\\n",
       "0  ['want', 'trade', 'someone', 'houston', 'ticke...   \n",
       "1                         ['cant', 'fall', 'asleep']   \n",
       "2  ['topic', 'map', 'talk', 'balisage', 'markup',...   \n",
       "3                                  ['cant', 'sleep']   \n",
       "4                           ['missed', 'bly', 'bus']   \n",
       "\n",
       "                                             synonym  \\\n",
       "0  [['privation', 'want', 'deprivation', 'needine...   \n",
       "1  [['buzzword', 'cant', 'bank', 'cant', 'camber'...   \n",
       "2  [['subject', 'topic', 'theme', 'topic', 'subje...   \n",
       "3  [['buzzword', 'cant', 'bank', 'cant', 'camber'...   \n",
       "4  [['miss', 'lose', 'miss', 'miss', 'neglect', '...   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0              want trade someone houston ticket one   \n",
       "1                                   cant fall asleep   \n",
       "2  topic map talk balisage markup conference prog...   \n",
       "3                                         cant sleep   \n",
       "4                                      missed bl bus   \n",
       "\n",
       "                                   clean_tweet_token  \n",
       "0  ['want', 'trade', 'someone', 'houston', 'ticke...  \n",
       "1                         ['cant', 'fall', 'asleep']  \n",
       "2  ['topic', 'map', 'talk', 'balisage', 'markup',...  \n",
       "3                                  ['cant', 'sleep']  \n",
       "4                            ['missed', 'bl', 'bus']  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_Dataset_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faabe7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8640d7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108628 entries, 0 to 108627\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   tweet_id           8356 non-null    float64\n",
      " 1   sentiment          108628 non-null  object \n",
      " 2   content            108628 non-null  object \n",
      " 3   content_token      8356 non-null    object \n",
      " 4   synonym            8356 non-null    object \n",
      " 5   clean_tweet        108391 non-null  object \n",
      " 6   clean_tweet_token  108628 non-null  object \n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "Tweet_Dataset_model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e4a8e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id             100272\n",
       "sentiment                 0\n",
       "content                   0\n",
       "content_token        100272\n",
       "synonym              100272\n",
       "clean_tweet             237\n",
       "clean_tweet_token         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_Dataset_model.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "564a63a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweet_Dataset_model = Tweet_Dataset_model[Tweet_Dataset_model['clean_tweet'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9badc91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "boredom       8356\n",
       "anger         8356\n",
       "relief        8353\n",
       "happiness     8352\n",
       "fun           8352\n",
       "love          8351\n",
       "sadness       8349\n",
       "hate          8344\n",
       "enthusiasm    8343\n",
       "worry         8335\n",
       "surprise      8324\n",
       "empty         8294\n",
       "neutral       8282\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_Dataset_model[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70ce511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_to_id  = {\"empty\":0, \"sadness\":1,\"enthusiasm\":2,\"neutral\":3,\"worry\":4,\n",
    "                        \"surprise\":5,\"love\":6,\"fun\":7,\"hate\":8,\"happiness\":9,\"boredom\":10,\"relief\":11,\"anger\":12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3fc6d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweet_Dataset_model[\"sentiment_id\"] = Tweet_Dataset_model['sentiment'].map(sent_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f955cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>content_token</th>\n",
       "      <th>synonym</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>clean_tweet_token</th>\n",
       "      <th>sentiment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.956968e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>['want', 'trade', 'someone', 'houston', 'ticke...</td>\n",
       "      <td>[['privation', 'want', 'deprivation', 'needine...</td>\n",
       "      <td>want trade someone houston ticket one</td>\n",
       "      <td>['want', 'trade', 'someone', 'houston', 'ticke...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.956969e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>cant fall asleep</td>\n",
       "      <td>['cant', 'fall', 'asleep']</td>\n",
       "      <td>[['buzzword', 'cant', 'bank', 'cant', 'camber'...</td>\n",
       "      <td>cant fall asleep</td>\n",
       "      <td>['cant', 'fall', 'asleep']</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.956972e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>No Topic Maps talks at the Balisage Markup Con...</td>\n",
       "      <td>['topic', 'map', 'talk', 'balisage', 'markup',...</td>\n",
       "      <td>[['subject', 'topic', 'theme', 'topic', 'subje...</td>\n",
       "      <td>topic map talk balisage markup conference prog...</td>\n",
       "      <td>['topic', 'map', 'talk', 'balisage', 'markup',...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.956975e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@cynthia_123 i cant sleep</td>\n",
       "      <td>['cant', 'sleep']</td>\n",
       "      <td>[['buzzword', 'cant', 'bank', 'cant', 'camber'...</td>\n",
       "      <td>cant sleep</td>\n",
       "      <td>['cant', 'sleep']</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.956976e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I missed the bl***y bus!!!!!!!!</td>\n",
       "      <td>['missed', 'bly', 'bus']</td>\n",
       "      <td>[['miss', 'lose', 'miss', 'miss', 'neglect', '...</td>\n",
       "      <td>missed bl bus</td>\n",
       "      <td>['missed', 'bl', 'bus']</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id sentiment                                            content  \\\n",
       "0  1.956968e+09   neutral  @dannycastillo We want to trade with someone w...   \n",
       "1  1.956969e+09   neutral                                   cant fall asleep   \n",
       "2  1.956972e+09   neutral  No Topic Maps talks at the Balisage Markup Con...   \n",
       "3  1.956975e+09   neutral                          @cynthia_123 i cant sleep   \n",
       "4  1.956976e+09   neutral                    I missed the bl***y bus!!!!!!!!   \n",
       "\n",
       "                                       content_token  \\\n",
       "0  ['want', 'trade', 'someone', 'houston', 'ticke...   \n",
       "1                         ['cant', 'fall', 'asleep']   \n",
       "2  ['topic', 'map', 'talk', 'balisage', 'markup',...   \n",
       "3                                  ['cant', 'sleep']   \n",
       "4                           ['missed', 'bly', 'bus']   \n",
       "\n",
       "                                             synonym  \\\n",
       "0  [['privation', 'want', 'deprivation', 'needine...   \n",
       "1  [['buzzword', 'cant', 'bank', 'cant', 'camber'...   \n",
       "2  [['subject', 'topic', 'theme', 'topic', 'subje...   \n",
       "3  [['buzzword', 'cant', 'bank', 'cant', 'camber'...   \n",
       "4  [['miss', 'lose', 'miss', 'miss', 'neglect', '...   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0              want trade someone houston ticket one   \n",
       "1                                   cant fall asleep   \n",
       "2  topic map talk balisage markup conference prog...   \n",
       "3                                         cant sleep   \n",
       "4                                      missed bl bus   \n",
       "\n",
       "                                   clean_tweet_token  sentiment_id  \n",
       "0  ['want', 'trade', 'someone', 'houston', 'ticke...             3  \n",
       "1                         ['cant', 'fall', 'asleep']             3  \n",
       "2  ['topic', 'map', 'talk', 'balisage', 'markup',...             3  \n",
       "3                                  ['cant', 'sleep']             3  \n",
       "4                            ['missed', 'bl', 'bus']             3  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet_Dataset_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7780b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf58fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with loading all necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a54fbcb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('day', 7989),\n",
       " ('get', 7304),\n",
       " ('quot', 5405),\n",
       " ('got', 4483),\n",
       " ('good', 4375),\n",
       " ('number', 4356),\n",
       " ('im', 4227),\n",
       " ('lol', 4209),\n",
       " ('one', 4170),\n",
       " ('know', 4121)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get most common words in training dataset\n",
    "from collections import Counter \n",
    "all_words = []\n",
    "for line in list(Tweet_Dataset_model['clean_tweet']):\n",
    "    words = line.split()\n",
    "    for word in words:\n",
    "        all_words.append(word.lower())\n",
    "    \n",
    "    \n",
    "a=Counter(all_words).most_common(10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a11d1897",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=Tweet_Dataset_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a43ed658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>content_token</th>\n",
       "      <th>synonym</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>clean_tweet_token</th>\n",
       "      <th>sentiment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.956968e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>['want', 'trade', 'someone', 'houston', 'ticke...</td>\n",
       "      <td>[['privation', 'want', 'deprivation', 'needine...</td>\n",
       "      <td>want trade someone houston ticket one</td>\n",
       "      <td>['want', 'trade', 'someone', 'houston', 'ticke...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.956969e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>cant fall asleep</td>\n",
       "      <td>['cant', 'fall', 'asleep']</td>\n",
       "      <td>[['buzzword', 'cant', 'bank', 'cant', 'camber'...</td>\n",
       "      <td>cant fall asleep</td>\n",
       "      <td>['cant', 'fall', 'asleep']</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.956972e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>No Topic Maps talks at the Balisage Markup Con...</td>\n",
       "      <td>['topic', 'map', 'talk', 'balisage', 'markup',...</td>\n",
       "      <td>[['subject', 'topic', 'theme', 'topic', 'subje...</td>\n",
       "      <td>topic map talk balisage markup conference prog...</td>\n",
       "      <td>['topic', 'map', 'talk', 'balisage', 'markup',...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.956975e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@cynthia_123 i cant sleep</td>\n",
       "      <td>['cant', 'sleep']</td>\n",
       "      <td>[['buzzword', 'cant', 'bank', 'cant', 'camber'...</td>\n",
       "      <td>cant sleep</td>\n",
       "      <td>['cant', 'sleep']</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.956976e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I missed the bl***y bus!!!!!!!!</td>\n",
       "      <td>['missed', 'bly', 'bus']</td>\n",
       "      <td>[['miss', 'lose', 'miss', 'miss', 'neglect', '...</td>\n",
       "      <td>missed bl bus</td>\n",
       "      <td>['missed', 'bl', 'bus']</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108623</th>\n",
       "      <td>NaN</td>\n",
       "      <td>anger</td>\n",
       "      <td>Did a historic Jesus of_all_time exist? Im wi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>historic jesus time exist im witness hard prov...</td>\n",
       "      <td>['historic', 'jesus', 'time', 'exist', 'im', '...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108624</th>\n",
       "      <td>NaN</td>\n",
       "      <td>anger</td>\n",
       "      <td>@mikeavila ack! I just interpret about your t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ack interpret testify horrible accounting taste</td>\n",
       "      <td>['ack', 'interpret', 'testify', 'horrible', 'a...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108625</th>\n",
       "      <td>NaN</td>\n",
       "      <td>anger</td>\n",
       "      <td>ne'er does anything dear cultivate and lapin ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ne er anything dear cultivate lapin life histo...</td>\n",
       "      <td>['ne', 'er', 'anything', 'dear', 'cultivate', ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108626</th>\n",
       "      <td>NaN</td>\n",
       "      <td>anger</td>\n",
       "      <td>@mashable Link to ff &amp;quot;how it works&amp;quot;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>link ff quot work quot broke</td>\n",
       "      <td>['link', 'ff', 'quot', 'work', 'quot', 'broke']</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108627</th>\n",
       "      <td>NaN</td>\n",
       "      <td>anger</td>\n",
       "      <td>I live begin to retrieve solarise blcok is a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live begin retrieve solarise blcok haox</td>\n",
       "      <td>['live', 'begin', 'retrieve', 'solarise', 'blc...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108391 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tweet_id sentiment  \\\n",
       "0       1.956968e+09   neutral   \n",
       "1       1.956969e+09   neutral   \n",
       "2       1.956972e+09   neutral   \n",
       "3       1.956975e+09   neutral   \n",
       "4       1.956976e+09   neutral   \n",
       "...              ...       ...   \n",
       "108623           NaN     anger   \n",
       "108624           NaN     anger   \n",
       "108625           NaN     anger   \n",
       "108626           NaN     anger   \n",
       "108627           NaN     anger   \n",
       "\n",
       "                                                  content  \\\n",
       "0       @dannycastillo We want to trade with someone w...   \n",
       "1                                        cant fall asleep   \n",
       "2       No Topic Maps talks at the Balisage Markup Con...   \n",
       "3                               @cynthia_123 i cant sleep   \n",
       "4                         I missed the bl***y bus!!!!!!!!   \n",
       "...                                                   ...   \n",
       "108623   Did a historic Jesus of_all_time exist? Im wi...   \n",
       "108624   @mikeavila ack! I just interpret about your t...   \n",
       "108625   ne'er does anything dear cultivate and lapin ...   \n",
       "108626   @mashable Link to ff &quot;how it works&quot;...   \n",
       "108627   I live begin to retrieve solarise blcok is a ...   \n",
       "\n",
       "                                            content_token  \\\n",
       "0       ['want', 'trade', 'someone', 'houston', 'ticke...   \n",
       "1                              ['cant', 'fall', 'asleep']   \n",
       "2       ['topic', 'map', 'talk', 'balisage', 'markup',...   \n",
       "3                                       ['cant', 'sleep']   \n",
       "4                                ['missed', 'bly', 'bus']   \n",
       "...                                                   ...   \n",
       "108623                                                NaN   \n",
       "108624                                                NaN   \n",
       "108625                                                NaN   \n",
       "108626                                                NaN   \n",
       "108627                                                NaN   \n",
       "\n",
       "                                                  synonym  \\\n",
       "0       [['privation', 'want', 'deprivation', 'needine...   \n",
       "1       [['buzzword', 'cant', 'bank', 'cant', 'camber'...   \n",
       "2       [['subject', 'topic', 'theme', 'topic', 'subje...   \n",
       "3       [['buzzword', 'cant', 'bank', 'cant', 'camber'...   \n",
       "4       [['miss', 'lose', 'miss', 'miss', 'neglect', '...   \n",
       "...                                                   ...   \n",
       "108623                                                NaN   \n",
       "108624                                                NaN   \n",
       "108625                                                NaN   \n",
       "108626                                                NaN   \n",
       "108627                                                NaN   \n",
       "\n",
       "                                              clean_tweet  \\\n",
       "0                   want trade someone houston ticket one   \n",
       "1                                        cant fall asleep   \n",
       "2       topic map talk balisage markup conference prog...   \n",
       "3                                              cant sleep   \n",
       "4                                           missed bl bus   \n",
       "...                                                   ...   \n",
       "108623  historic jesus time exist im witness hard prov...   \n",
       "108624    ack interpret testify horrible accounting taste   \n",
       "108625  ne er anything dear cultivate lapin life histo...   \n",
       "108626                       link ff quot work quot broke   \n",
       "108627            live begin retrieve solarise blcok haox   \n",
       "\n",
       "                                        clean_tweet_token  sentiment_id  \n",
       "0       ['want', 'trade', 'someone', 'houston', 'ticke...             3  \n",
       "1                              ['cant', 'fall', 'asleep']             3  \n",
       "2       ['topic', 'map', 'talk', 'balisage', 'markup',...             3  \n",
       "3                                       ['cant', 'sleep']             3  \n",
       "4                                 ['missed', 'bl', 'bus']             3  \n",
       "...                                                   ...           ...  \n",
       "108623  ['historic', 'jesus', 'time', 'exist', 'im', '...            12  \n",
       "108624  ['ack', 'interpret', 'testify', 'horrible', 'a...            12  \n",
       "108625  ['ne', 'er', 'anything', 'dear', 'cultivate', ...            12  \n",
       "108626    ['link', 'ff', 'quot', 'work', 'quot', 'broke']            12  \n",
       "108627  ['live', 'begin', 'retrieve', 'solarise', 'blc...            12  \n",
       "\n",
       "[108391 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2224e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>content_token</th>\n",
       "      <th>synonym</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>clean_tweet_token</th>\n",
       "      <th>sentiment_id</th>\n",
       "      <th>new_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.956968e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>['want', 'trade', 'someone', 'houston', 'ticke...</td>\n",
       "      <td>[['privation', 'want', 'deprivation', 'needine...</td>\n",
       "      <td>want trade someone houston ticket one</td>\n",
       "      <td>['want', 'trade', 'someone', 'houston', 'ticke...</td>\n",
       "      <td>3</td>\n",
       "      <td>dannycastillo We want to trade with someone wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.956969e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>cant fall asleep</td>\n",
       "      <td>['cant', 'fall', 'asleep']</td>\n",
       "      <td>[['buzzword', 'cant', 'bank', 'cant', 'camber'...</td>\n",
       "      <td>cant fall asleep</td>\n",
       "      <td>['cant', 'fall', 'asleep']</td>\n",
       "      <td>3</td>\n",
       "      <td>cant fall asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.956972e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>No Topic Maps talks at the Balisage Markup Con...</td>\n",
       "      <td>['topic', 'map', 'talk', 'balisage', 'markup',...</td>\n",
       "      <td>[['subject', 'topic', 'theme', 'topic', 'subje...</td>\n",
       "      <td>topic map talk balisage markup conference prog...</td>\n",
       "      <td>['topic', 'map', 'talk', 'balisage', 'markup',...</td>\n",
       "      <td>3</td>\n",
       "      <td>No Topic Maps talks at the Balisage Markup Con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.956975e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@cynthia_123 i cant sleep</td>\n",
       "      <td>['cant', 'sleep']</td>\n",
       "      <td>[['buzzword', 'cant', 'bank', 'cant', 'camber'...</td>\n",
       "      <td>cant sleep</td>\n",
       "      <td>['cant', 'sleep']</td>\n",
       "      <td>3</td>\n",
       "      <td>cynthia_123 i cant sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.956976e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I missed the bl***y bus!!!!!!!!</td>\n",
       "      <td>['missed', 'bly', 'bus']</td>\n",
       "      <td>[['miss', 'lose', 'miss', 'miss', 'neglect', '...</td>\n",
       "      <td>missed bl bus</td>\n",
       "      <td>['missed', 'bl', 'bus']</td>\n",
       "      <td>3</td>\n",
       "      <td>I missed the bl***y bus!!!!!!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id sentiment                                            content  \\\n",
       "0  1.956968e+09   neutral  @dannycastillo We want to trade with someone w...   \n",
       "1  1.956969e+09   neutral                                   cant fall asleep   \n",
       "2  1.956972e+09   neutral  No Topic Maps talks at the Balisage Markup Con...   \n",
       "3  1.956975e+09   neutral                          @cynthia_123 i cant sleep   \n",
       "4  1.956976e+09   neutral                    I missed the bl***y bus!!!!!!!!   \n",
       "\n",
       "                                       content_token  \\\n",
       "0  ['want', 'trade', 'someone', 'houston', 'ticke...   \n",
       "1                         ['cant', 'fall', 'asleep']   \n",
       "2  ['topic', 'map', 'talk', 'balisage', 'markup',...   \n",
       "3                                  ['cant', 'sleep']   \n",
       "4                           ['missed', 'bly', 'bus']   \n",
       "\n",
       "                                             synonym  \\\n",
       "0  [['privation', 'want', 'deprivation', 'needine...   \n",
       "1  [['buzzword', 'cant', 'bank', 'cant', 'camber'...   \n",
       "2  [['subject', 'topic', 'theme', 'topic', 'subje...   \n",
       "3  [['buzzword', 'cant', 'bank', 'cant', 'camber'...   \n",
       "4  [['miss', 'lose', 'miss', 'miss', 'neglect', '...   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0              want trade someone houston ticket one   \n",
       "1                                   cant fall asleep   \n",
       "2  topic map talk balisage markup conference prog...   \n",
       "3                                         cant sleep   \n",
       "4                                      missed bl bus   \n",
       "\n",
       "                                   clean_tweet_token  sentiment_id  \\\n",
       "0  ['want', 'trade', 'someone', 'houston', 'ticke...             3   \n",
       "1                         ['cant', 'fall', 'asleep']             3   \n",
       "2  ['topic', 'map', 'talk', 'balisage', 'markup',...             3   \n",
       "3                                  ['cant', 'sleep']             3   \n",
       "4                            ['missed', 'bl', 'bus']             3   \n",
       "\n",
       "                                           new_tweet  \n",
       "0  dannycastillo We want to trade with someone wh...  \n",
       "1                                   cant fall asleep  \n",
       "2  No Topic Maps talks at the Balisage Markup Con...  \n",
       "3                           cynthia_123 i cant sleep  \n",
       "4                    I missed the bl***y bus!!!!!!!!  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing usernames from tweet\n",
    "\n",
    "data['new_tweet'] = data.content.str.replace('@', '')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "411f3603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>content_token</th>\n",
       "      <th>synonym</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>clean_tweet_token</th>\n",
       "      <th>sentiment_id</th>\n",
       "      <th>new_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.956968e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>['want', 'trade', 'someone', 'houston', 'ticke...</td>\n",
       "      <td>[['privation', 'want', 'deprivation', 'needine...</td>\n",
       "      <td>want trade someone houston ticket one</td>\n",
       "      <td>['want', 'trade', 'someone', 'houston', 'ticke...</td>\n",
       "      <td>3</td>\n",
       "      <td>dannycastillo We want to trade with someone wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.956969e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>cant fall asleep</td>\n",
       "      <td>['cant', 'fall', 'asleep']</td>\n",
       "      <td>[['buzzword', 'cant', 'bank', 'cant', 'camber'...</td>\n",
       "      <td>cant fall asleep</td>\n",
       "      <td>['cant', 'fall', 'asleep']</td>\n",
       "      <td>3</td>\n",
       "      <td>cant fall asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.956972e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>No Topic Maps talks at the Balisage Markup Con...</td>\n",
       "      <td>['topic', 'map', 'talk', 'balisage', 'markup',...</td>\n",
       "      <td>[['subject', 'topic', 'theme', 'topic', 'subje...</td>\n",
       "      <td>topic map talk balisage markup conference prog...</td>\n",
       "      <td>['topic', 'map', 'talk', 'balisage', 'markup',...</td>\n",
       "      <td>3</td>\n",
       "      <td>No Topic Maps talks at the Balisage Markup Con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.956975e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@cynthia_123 i cant sleep</td>\n",
       "      <td>['cant', 'sleep']</td>\n",
       "      <td>[['buzzword', 'cant', 'bank', 'cant', 'camber'...</td>\n",
       "      <td>cant sleep</td>\n",
       "      <td>['cant', 'sleep']</td>\n",
       "      <td>3</td>\n",
       "      <td>cynthia     i cant sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.956976e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I missed the bl***y bus!!!!!!!!</td>\n",
       "      <td>['missed', 'bly', 'bus']</td>\n",
       "      <td>[['miss', 'lose', 'miss', 'miss', 'neglect', '...</td>\n",
       "      <td>missed bl bus</td>\n",
       "      <td>['missed', 'bl', 'bus']</td>\n",
       "      <td>3</td>\n",
       "      <td>I missed the bl   y bus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id sentiment                                            content  \\\n",
       "0  1.956968e+09   neutral  @dannycastillo We want to trade with someone w...   \n",
       "1  1.956969e+09   neutral                                   cant fall asleep   \n",
       "2  1.956972e+09   neutral  No Topic Maps talks at the Balisage Markup Con...   \n",
       "3  1.956975e+09   neutral                          @cynthia_123 i cant sleep   \n",
       "4  1.956976e+09   neutral                    I missed the bl***y bus!!!!!!!!   \n",
       "\n",
       "                                       content_token  \\\n",
       "0  ['want', 'trade', 'someone', 'houston', 'ticke...   \n",
       "1                         ['cant', 'fall', 'asleep']   \n",
       "2  ['topic', 'map', 'talk', 'balisage', 'markup',...   \n",
       "3                                  ['cant', 'sleep']   \n",
       "4                           ['missed', 'bly', 'bus']   \n",
       "\n",
       "                                             synonym  \\\n",
       "0  [['privation', 'want', 'deprivation', 'needine...   \n",
       "1  [['buzzword', 'cant', 'bank', 'cant', 'camber'...   \n",
       "2  [['subject', 'topic', 'theme', 'topic', 'subje...   \n",
       "3  [['buzzword', 'cant', 'bank', 'cant', 'camber'...   \n",
       "4  [['miss', 'lose', 'miss', 'miss', 'neglect', '...   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0              want trade someone houston ticket one   \n",
       "1                                   cant fall asleep   \n",
       "2  topic map talk balisage markup conference prog...   \n",
       "3                                         cant sleep   \n",
       "4                                      missed bl bus   \n",
       "\n",
       "                                   clean_tweet_token  sentiment_id  \\\n",
       "0  ['want', 'trade', 'someone', 'houston', 'ticke...             3   \n",
       "1                         ['cant', 'fall', 'asleep']             3   \n",
       "2  ['topic', 'map', 'talk', 'balisage', 'markup',...             3   \n",
       "3                                  ['cant', 'sleep']             3   \n",
       "4                            ['missed', 'bl', 'bus']             3   \n",
       "\n",
       "                                           new_tweet  \n",
       "0  dannycastillo We want to trade with someone wh...  \n",
       "1                                   cant fall asleep  \n",
       "2  No Topic Maps talks at the Balisage Markup Con...  \n",
       "3                           cynthia     i cant sleep  \n",
       "4                    I missed the bl   y bus          "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing Punctuations, Numbers, and Special Characters\n",
    "#[a-zA-Z] = Any single character in the range a-z or A-Z\n",
    "# ^ = Start of line \n",
    "# $ = End of line \n",
    "\n",
    "data['new_tweet'] = data['new_tweet'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "data['new_tweet'] = data['new_tweet'].str.replace(\"#\", \"\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9bf06dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 55857),\n",
       " ('to', 41046),\n",
       " ('the', 38474),\n",
       " ('a', 29495),\n",
       " ('it', 22771),\n",
       " ('my', 22267),\n",
       " ('and', 22028),\n",
       " ('you', 20468),\n",
       " ('is', 16624),\n",
       " ('for', 15894)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get most common words in training dataset\n",
    "from collections import Counter \n",
    "all_words = []\n",
    "for line in list(data['new_tweet']):\n",
    "    words = line.split()\n",
    "    for word in words:\n",
    "        all_words.append(word.lower())\n",
    "    \n",
    "    \n",
    "a=Counter(all_words).most_common(10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0c19715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>content_token</th>\n",
       "      <th>synonym</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>clean_tweet_token</th>\n",
       "      <th>sentiment_id</th>\n",
       "      <th>new_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.956968e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>['want', 'trade', 'someone', 'houston', 'ticke...</td>\n",
       "      <td>[['privation', 'want', 'deprivation', 'needine...</td>\n",
       "      <td>want trade someone houston ticket one</td>\n",
       "      <td>['want', 'trade', 'someone', 'houston', 'ticke...</td>\n",
       "      <td>3</td>\n",
       "      <td>[dannycastillo, We, want, to, trade, with, som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.956969e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>cant fall asleep</td>\n",
       "      <td>['cant', 'fall', 'asleep']</td>\n",
       "      <td>[['buzzword', 'cant', 'bank', 'cant', 'camber'...</td>\n",
       "      <td>cant fall asleep</td>\n",
       "      <td>['cant', 'fall', 'asleep']</td>\n",
       "      <td>3</td>\n",
       "      <td>[cant, fall, asleep]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.956972e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>No Topic Maps talks at the Balisage Markup Con...</td>\n",
       "      <td>['topic', 'map', 'talk', 'balisage', 'markup',...</td>\n",
       "      <td>[['subject', 'topic', 'theme', 'topic', 'subje...</td>\n",
       "      <td>topic map talk balisage markup conference prog...</td>\n",
       "      <td>['topic', 'map', 'talk', 'balisage', 'markup',...</td>\n",
       "      <td>3</td>\n",
       "      <td>[No, Topic, Maps, talks, at, the, Balisage, Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.956975e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@cynthia_123 i cant sleep</td>\n",
       "      <td>['cant', 'sleep']</td>\n",
       "      <td>[['buzzword', 'cant', 'bank', 'cant', 'camber'...</td>\n",
       "      <td>cant sleep</td>\n",
       "      <td>['cant', 'sleep']</td>\n",
       "      <td>3</td>\n",
       "      <td>[cynthia, i, cant, sleep]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.956976e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I missed the bl***y bus!!!!!!!!</td>\n",
       "      <td>['missed', 'bly', 'bus']</td>\n",
       "      <td>[['miss', 'lose', 'miss', 'miss', 'neglect', '...</td>\n",
       "      <td>missed bl bus</td>\n",
       "      <td>['missed', 'bl', 'bus']</td>\n",
       "      <td>3</td>\n",
       "      <td>[I, missed, the, bl, y, bus]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id sentiment                                            content  \\\n",
       "0  1.956968e+09   neutral  @dannycastillo We want to trade with someone w...   \n",
       "1  1.956969e+09   neutral                                   cant fall asleep   \n",
       "2  1.956972e+09   neutral  No Topic Maps talks at the Balisage Markup Con...   \n",
       "3  1.956975e+09   neutral                          @cynthia_123 i cant sleep   \n",
       "4  1.956976e+09   neutral                    I missed the bl***y bus!!!!!!!!   \n",
       "\n",
       "                                       content_token  \\\n",
       "0  ['want', 'trade', 'someone', 'houston', 'ticke...   \n",
       "1                         ['cant', 'fall', 'asleep']   \n",
       "2  ['topic', 'map', 'talk', 'balisage', 'markup',...   \n",
       "3                                  ['cant', 'sleep']   \n",
       "4                           ['missed', 'bly', 'bus']   \n",
       "\n",
       "                                             synonym  \\\n",
       "0  [['privation', 'want', 'deprivation', 'needine...   \n",
       "1  [['buzzword', 'cant', 'bank', 'cant', 'camber'...   \n",
       "2  [['subject', 'topic', 'theme', 'topic', 'subje...   \n",
       "3  [['buzzword', 'cant', 'bank', 'cant', 'camber'...   \n",
       "4  [['miss', 'lose', 'miss', 'miss', 'neglect', '...   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0              want trade someone houston ticket one   \n",
       "1                                   cant fall asleep   \n",
       "2  topic map talk balisage markup conference prog...   \n",
       "3                                         cant sleep   \n",
       "4                                      missed bl bus   \n",
       "\n",
       "                                   clean_tweet_token  sentiment_id  \\\n",
       "0  ['want', 'trade', 'someone', 'houston', 'ticke...             3   \n",
       "1                         ['cant', 'fall', 'asleep']             3   \n",
       "2  ['topic', 'map', 'talk', 'balisage', 'markup',...             3   \n",
       "3                                  ['cant', 'sleep']             3   \n",
       "4                            ['missed', 'bl', 'bus']             3   \n",
       "\n",
       "                                           new_tweet  \n",
       "0  [dannycastillo, We, want, to, trade, with, som...  \n",
       "1                               [cant, fall, asleep]  \n",
       "2  [No, Topic, Maps, talks, at, the, Balisage, Ma...  \n",
       "3                          [cynthia, i, cant, sleep]  \n",
       "4                       [I, missed, the, bl, y, bus]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenization\n",
    "data['new_tweet'] = data['new_tweet'].apply(lambda x: x.split())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "925113a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>content_token</th>\n",
       "      <th>synonym</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>clean_tweet_token</th>\n",
       "      <th>sentiment_id</th>\n",
       "      <th>new_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.956968e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>['want', 'trade', 'someone', 'houston', 'ticke...</td>\n",
       "      <td>[['privation', 'want', 'deprivation', 'needine...</td>\n",
       "      <td>want trade someone houston ticket one</td>\n",
       "      <td>['want', 'trade', 'someone', 'houston', 'ticke...</td>\n",
       "      <td>3</td>\n",
       "      <td>[dannycastillo, we, want, to, trade, with, som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.956969e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>cant fall asleep</td>\n",
       "      <td>['cant', 'fall', 'asleep']</td>\n",
       "      <td>[['buzzword', 'cant', 'bank', 'cant', 'camber'...</td>\n",
       "      <td>cant fall asleep</td>\n",
       "      <td>['cant', 'fall', 'asleep']</td>\n",
       "      <td>3</td>\n",
       "      <td>[cant, fall, asleep]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.956972e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>No Topic Maps talks at the Balisage Markup Con...</td>\n",
       "      <td>['topic', 'map', 'talk', 'balisage', 'markup',...</td>\n",
       "      <td>[['subject', 'topic', 'theme', 'topic', 'subje...</td>\n",
       "      <td>topic map talk balisage markup conference prog...</td>\n",
       "      <td>['topic', 'map', 'talk', 'balisage', 'markup',...</td>\n",
       "      <td>3</td>\n",
       "      <td>[no, topic, map, talk, at, the, balisag, marku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.956975e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@cynthia_123 i cant sleep</td>\n",
       "      <td>['cant', 'sleep']</td>\n",
       "      <td>[['buzzword', 'cant', 'bank', 'cant', 'camber'...</td>\n",
       "      <td>cant sleep</td>\n",
       "      <td>['cant', 'sleep']</td>\n",
       "      <td>3</td>\n",
       "      <td>[cynthia, i, cant, sleep]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.956976e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I missed the bl***y bus!!!!!!!!</td>\n",
       "      <td>['missed', 'bly', 'bus']</td>\n",
       "      <td>[['miss', 'lose', 'miss', 'miss', 'neglect', '...</td>\n",
       "      <td>missed bl bus</td>\n",
       "      <td>['missed', 'bl', 'bus']</td>\n",
       "      <td>3</td>\n",
       "      <td>[i, miss, the, bl, y, bus]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id sentiment                                            content  \\\n",
       "0  1.956968e+09   neutral  @dannycastillo We want to trade with someone w...   \n",
       "1  1.956969e+09   neutral                                   cant fall asleep   \n",
       "2  1.956972e+09   neutral  No Topic Maps talks at the Balisage Markup Con...   \n",
       "3  1.956975e+09   neutral                          @cynthia_123 i cant sleep   \n",
       "4  1.956976e+09   neutral                    I missed the bl***y bus!!!!!!!!   \n",
       "\n",
       "                                       content_token  \\\n",
       "0  ['want', 'trade', 'someone', 'houston', 'ticke...   \n",
       "1                         ['cant', 'fall', 'asleep']   \n",
       "2  ['topic', 'map', 'talk', 'balisage', 'markup',...   \n",
       "3                                  ['cant', 'sleep']   \n",
       "4                           ['missed', 'bly', 'bus']   \n",
       "\n",
       "                                             synonym  \\\n",
       "0  [['privation', 'want', 'deprivation', 'needine...   \n",
       "1  [['buzzword', 'cant', 'bank', 'cant', 'camber'...   \n",
       "2  [['subject', 'topic', 'theme', 'topic', 'subje...   \n",
       "3  [['buzzword', 'cant', 'bank', 'cant', 'camber'...   \n",
       "4  [['miss', 'lose', 'miss', 'miss', 'neglect', '...   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0              want trade someone houston ticket one   \n",
       "1                                   cant fall asleep   \n",
       "2  topic map talk balisage markup conference prog...   \n",
       "3                                         cant sleep   \n",
       "4                                      missed bl bus   \n",
       "\n",
       "                                   clean_tweet_token  sentiment_id  \\\n",
       "0  ['want', 'trade', 'someone', 'houston', 'ticke...             3   \n",
       "1                         ['cant', 'fall', 'asleep']             3   \n",
       "2  ['topic', 'map', 'talk', 'balisage', 'markup',...             3   \n",
       "3                                  ['cant', 'sleep']             3   \n",
       "4                            ['missed', 'bl', 'bus']             3   \n",
       "\n",
       "                                           new_tweet  \n",
       "0  [dannycastillo, we, want, to, trade, with, som...  \n",
       "1                               [cant, fall, asleep]  \n",
       "2  [no, topic, map, talk, at, the, balisag, marku...  \n",
       "3                          [cynthia, i, cant, sleep]  \n",
       "4                         [i, miss, the, bl, y, bus]  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "data['new_tweet']= data['new_tweet'].apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbe26210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fatma.er\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e5dc9446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#stopwords = set(stopwords.words('english'))\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "198b9cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "newStopWords = ['u','go','got','via','or','ur','us','in','i','let','the','to','is','amp','make','one','day','days','get']\n",
    "stopwords.extend(newStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "edb4daea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "\n",
    "def process(text):\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = set(char for char in list(text) if char not in string.punctuation)\n",
    "    # Join the characters to form the string.\n",
    "    nopunc = \" \".join(nopunc)\n",
    "    # remove any stopwords if present\n",
    "    return [word for word in nopunc.lower().split() if word.lower() not in stopwords]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4852ad0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>content_token</th>\n",
       "      <th>synonym</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>clean_tweet_token</th>\n",
       "      <th>sentiment_id</th>\n",
       "      <th>new_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.956968e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>['want', 'trade', 'someone', 'houston', 'ticke...</td>\n",
       "      <td>[['privation', 'want', 'deprivation', 'needine...</td>\n",
       "      <td>want trade someone houston ticket one</td>\n",
       "      <td>['want', 'trade', 'someone', 'houston', 'ticke...</td>\n",
       "      <td>3</td>\n",
       "      <td>[trade, ticket, dannycastillo, someon, want, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.956969e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>cant fall asleep</td>\n",
       "      <td>['cant', 'fall', 'asleep']</td>\n",
       "      <td>[['buzzword', 'cant', 'bank', 'cant', 'camber'...</td>\n",
       "      <td>cant fall asleep</td>\n",
       "      <td>['cant', 'fall', 'asleep']</td>\n",
       "      <td>3</td>\n",
       "      <td>[cant, fall, asleep]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.956972e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>No Topic Maps talks at the Balisage Markup Con...</td>\n",
       "      <td>['topic', 'map', 'talk', 'balisage', 'markup',...</td>\n",
       "      <td>[['subject', 'topic', 'theme', 'topic', 'subje...</td>\n",
       "      <td>topic map talk balisage markup conference prog...</td>\n",
       "      <td>['topic', 'map', 'talk', 'balisage', 'markup',...</td>\n",
       "      <td>3</td>\n",
       "      <td>[ml, topic, onlin, balisag, topicmap, bobdc, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.956975e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@cynthia_123 i cant sleep</td>\n",
       "      <td>['cant', 'sleep']</td>\n",
       "      <td>[['buzzword', 'cant', 'bank', 'cant', 'camber'...</td>\n",
       "      <td>cant sleep</td>\n",
       "      <td>['cant', 'sleep']</td>\n",
       "      <td>3</td>\n",
       "      <td>[cant, cynthia, sleep]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.956976e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I missed the bl***y bus!!!!!!!!</td>\n",
       "      <td>['missed', 'bly', 'bus']</td>\n",
       "      <td>[['miss', 'lose', 'miss', 'miss', 'neglect', '...</td>\n",
       "      <td>missed bl bus</td>\n",
       "      <td>['missed', 'bl', 'bus']</td>\n",
       "      <td>3</td>\n",
       "      <td>[bl, bus, miss]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id sentiment                                            content  \\\n",
       "0  1.956968e+09   neutral  @dannycastillo We want to trade with someone w...   \n",
       "1  1.956969e+09   neutral                                   cant fall asleep   \n",
       "2  1.956972e+09   neutral  No Topic Maps talks at the Balisage Markup Con...   \n",
       "3  1.956975e+09   neutral                          @cynthia_123 i cant sleep   \n",
       "4  1.956976e+09   neutral                    I missed the bl***y bus!!!!!!!!   \n",
       "\n",
       "                                       content_token  \\\n",
       "0  ['want', 'trade', 'someone', 'houston', 'ticke...   \n",
       "1                         ['cant', 'fall', 'asleep']   \n",
       "2  ['topic', 'map', 'talk', 'balisage', 'markup',...   \n",
       "3                                  ['cant', 'sleep']   \n",
       "4                           ['missed', 'bly', 'bus']   \n",
       "\n",
       "                                             synonym  \\\n",
       "0  [['privation', 'want', 'deprivation', 'needine...   \n",
       "1  [['buzzword', 'cant', 'bank', 'cant', 'camber'...   \n",
       "2  [['subject', 'topic', 'theme', 'topic', 'subje...   \n",
       "3  [['buzzword', 'cant', 'bank', 'cant', 'camber'...   \n",
       "4  [['miss', 'lose', 'miss', 'miss', 'neglect', '...   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0              want trade someone houston ticket one   \n",
       "1                                   cant fall asleep   \n",
       "2  topic map talk balisage markup conference prog...   \n",
       "3                                         cant sleep   \n",
       "4                                      missed bl bus   \n",
       "\n",
       "                                   clean_tweet_token  sentiment_id  \\\n",
       "0  ['want', 'trade', 'someone', 'houston', 'ticke...             3   \n",
       "1                         ['cant', 'fall', 'asleep']             3   \n",
       "2  ['topic', 'map', 'talk', 'balisage', 'markup',...             3   \n",
       "3                                  ['cant', 'sleep']             3   \n",
       "4                            ['missed', 'bl', 'bus']             3   \n",
       "\n",
       "                                           new_tweet  \n",
       "0  [trade, ticket, dannycastillo, someon, want, h...  \n",
       "1                               [cant, fall, asleep]  \n",
       "2  [ml, topic, onlin, balisag, topicmap, bobdc, t...  \n",
       "3                             [cant, cynthia, sleep]  \n",
       "4                                    [bl, bus, miss]  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['new_tweet'] = data['new_tweet'].apply(process) \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7232cefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>content_token</th>\n",
       "      <th>synonym</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>clean_tweet_token</th>\n",
       "      <th>sentiment_id</th>\n",
       "      <th>new_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.956968e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>['want', 'trade', 'someone', 'houston', 'ticke...</td>\n",
       "      <td>[['privation', 'want', 'deprivation', 'needine...</td>\n",
       "      <td>want trade someone houston ticket one</td>\n",
       "      <td>['want', 'trade', 'someone', 'houston', 'ticke...</td>\n",
       "      <td>3</td>\n",
       "      <td>trade ticket dannycastillo someon want houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.956969e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>cant fall asleep</td>\n",
       "      <td>['cant', 'fall', 'asleep']</td>\n",
       "      <td>[['buzzword', 'cant', 'bank', 'cant', 'camber'...</td>\n",
       "      <td>cant fall asleep</td>\n",
       "      <td>['cant', 'fall', 'asleep']</td>\n",
       "      <td>3</td>\n",
       "      <td>cant fall asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.956972e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>No Topic Maps talks at the Balisage Markup Con...</td>\n",
       "      <td>['topic', 'map', 'talk', 'balisage', 'markup',...</td>\n",
       "      <td>[['subject', 'topic', 'theme', 'topic', 'subje...</td>\n",
       "      <td>topic map talk balisage markup conference prog...</td>\n",
       "      <td>['topic', 'map', 'talk', 'balisage', 'markup',...</td>\n",
       "      <td>3</td>\n",
       "      <td>ml topic onlin balisag topicmap bobdc talk pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.956975e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@cynthia_123 i cant sleep</td>\n",
       "      <td>['cant', 'sleep']</td>\n",
       "      <td>[['buzzword', 'cant', 'bank', 'cant', 'camber'...</td>\n",
       "      <td>cant sleep</td>\n",
       "      <td>['cant', 'sleep']</td>\n",
       "      <td>3</td>\n",
       "      <td>cant cynthia sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.956976e+09</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I missed the bl***y bus!!!!!!!!</td>\n",
       "      <td>['missed', 'bly', 'bus']</td>\n",
       "      <td>[['miss', 'lose', 'miss', 'miss', 'neglect', '...</td>\n",
       "      <td>missed bl bus</td>\n",
       "      <td>['missed', 'bl', 'bus']</td>\n",
       "      <td>3</td>\n",
       "      <td>bl bus miss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id sentiment                                            content  \\\n",
       "0  1.956968e+09   neutral  @dannycastillo We want to trade with someone w...   \n",
       "1  1.956969e+09   neutral                                   cant fall asleep   \n",
       "2  1.956972e+09   neutral  No Topic Maps talks at the Balisage Markup Con...   \n",
       "3  1.956975e+09   neutral                          @cynthia_123 i cant sleep   \n",
       "4  1.956976e+09   neutral                    I missed the bl***y bus!!!!!!!!   \n",
       "\n",
       "                                       content_token  \\\n",
       "0  ['want', 'trade', 'someone', 'houston', 'ticke...   \n",
       "1                         ['cant', 'fall', 'asleep']   \n",
       "2  ['topic', 'map', 'talk', 'balisage', 'markup',...   \n",
       "3                                  ['cant', 'sleep']   \n",
       "4                           ['missed', 'bly', 'bus']   \n",
       "\n",
       "                                             synonym  \\\n",
       "0  [['privation', 'want', 'deprivation', 'needine...   \n",
       "1  [['buzzword', 'cant', 'bank', 'cant', 'camber'...   \n",
       "2  [['subject', 'topic', 'theme', 'topic', 'subje...   \n",
       "3  [['buzzword', 'cant', 'bank', 'cant', 'camber'...   \n",
       "4  [['miss', 'lose', 'miss', 'miss', 'neglect', '...   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0              want trade someone houston ticket one   \n",
       "1                                   cant fall asleep   \n",
       "2  topic map talk balisage markup conference prog...   \n",
       "3                                         cant sleep   \n",
       "4                                      missed bl bus   \n",
       "\n",
       "                                   clean_tweet_token  sentiment_id  \\\n",
       "0  ['want', 'trade', 'someone', 'houston', 'ticke...             3   \n",
       "1                         ['cant', 'fall', 'asleep']             3   \n",
       "2  ['topic', 'map', 'talk', 'balisage', 'markup',...             3   \n",
       "3                                  ['cant', 'sleep']             3   \n",
       "4                            ['missed', 'bl', 'bus']             3   \n",
       "\n",
       "                                           new_tweet  \n",
       "0     trade ticket dannycastillo someon want houston  \n",
       "1                                   cant fall asleep  \n",
       "2  ml topic onlin balisag topicmap bobdc talk pro...  \n",
       "3                                 cant cynthia sleep  \n",
       "4                                        bl bus miss  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def string (text):\n",
    "    to_return=\"\"\n",
    "    for i in list(text):\n",
    "        to_return += str(i) + \" \"\n",
    "    to_return = to_return[:-1]\n",
    "    \n",
    "    return to_return\n",
    "    \n",
    "       \n",
    "data['new_tweet'] = data['new_tweet'].apply(string)\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c29618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ff89edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set : (86712,) (86712,)\n",
      "testing set : (21679,) (21679,)\n"
     ]
    }
   ],
   "source": [
    "#Split data into training and testing sets \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data[\"new_tweet\"], \n",
    "                                                    data[\"sentiment_id\"], test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(\"training set :\",x_train.shape,y_train.shape)\n",
    "print(\"testing set :\",x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "020270f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "transformer = TfidfTransformer(norm='l2',sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0855da30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86712, 39890)\n",
      "(86712, 39890)\n"
     ]
    }
   ],
   "source": [
    "x_train_counts = count_vect.fit_transform(x_train)\n",
    "x_train_tfidf = transformer.fit_transform(x_train_counts)\n",
    "\n",
    "print(x_train_counts.shape)\n",
    "print(x_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bc981b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21679, 39890)\n",
      "(21679, 39890)\n"
     ]
    }
   ],
   "source": [
    "x_test_counts = count_vect.transform(x_test)\n",
    "x_test_tfidf = transformer.transform(x_test_counts)\n",
    "\n",
    "print(x_test_counts.shape)\n",
    "print(x_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989fe97f",
   "metadata": {},
   "source": [
    "# Model building  Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ea5fa0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=200)\n",
    "model.fit(x_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "df87732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c5bcce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.99132801328474"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predictions)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eece8f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1557,   11,   11,   31,   21,   17,    8,   11,   15,    6,    8,\n",
       "           7,    0],\n",
       "       [  40,  718,   23,  232,  276,   59,   57,   62,   69,   72,   19,\n",
       "          35,    4],\n",
       "       [  12,   11, 1480,   18,    8,   11,   16,    3,   14,   11,    4,\n",
       "           5,    0],\n",
       "       [  41,  125,   24,  737,  262,   56,  100,   50,   35,  184,   11,\n",
       "          51,    8],\n",
       "       [  27,  257,   23,  437,  502,   55,   76,   44,   61,  152,   12,\n",
       "          39,   10],\n",
       "       [  33,   50,   20,   98,   54, 1279,   38,   34,   28,   44,    4,\n",
       "          31,    3],\n",
       "       [  21,   47,   24,  133,   71,   56, 1126,   40,   38,  141,    3,\n",
       "          28,    0],\n",
       "       [  18,   18,   18,   76,   35,   46,   37, 1379,   30,   45,    4,\n",
       "          22,    2],\n",
       "       [  20,   14,   13,   47,   27,   28,   12,   13, 1403,    5,    8,\n",
       "          12,    1],\n",
       "       [  18,   31,   22,  205,   93,   56,  144,   86,   23,  880,    3,\n",
       "          65,    4],\n",
       "       [   0,    4,    0,    7,    1,    2,    0,    2,    3,    2, 1611,\n",
       "           1,    0],\n",
       "       [  25,   22,   19,   72,   36,   44,   41,   25,   25,   49,    4,\n",
       "        1316,    1],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0, 1619]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "38ff4220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  0,  8, ...,  0,  6,  9], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422bd0f3",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "df1f080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/Shrneha/Twitter-sentiment-analysis/blob/master/Twitter.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "63001312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=400)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression(random_state=400 )\n",
    "logmodel.fit(x_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fa22d458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='warn', random_state=400, solver='warn')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
    "          n_jobs=None, penalty='l2', random_state=400, solver='warn',\n",
    "          tol=0.0001, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "79547fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_predictions = logmodel.predict(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e618820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1393,   34,   36,   39,   34,   15,   14,   11,   26,   27,   21,\n",
       "          46,    7],\n",
       "       [  82,  585,   60,  151,  263,   75,   55,   78,  124,   66,   42,\n",
       "          68,   17],\n",
       "       [  14,   19, 1384,   24,   20,   20,   19,   21,   18,   18,    9,\n",
       "          25,    2],\n",
       "       [  69,  119,   51,  580,  251,   76,   97,   97,   59,  159,   22,\n",
       "          77,   27],\n",
       "       [  50,  230,   59,  264,  566,   86,   54,   79,   82,  120,   28,\n",
       "          54,   23],\n",
       "       [  54,   82,   57,  106,   83,  903,   78,   88,   70,  100,   25,\n",
       "          59,   11],\n",
       "       [  40,   46,   60,  112,   68,   53,  889,  102,   34,  215,   13,\n",
       "          90,    6],\n",
       "       [  35,   38,   44,   60,   43,   61,   64, 1154,   36,  113,   11,\n",
       "          64,    7],\n",
       "       [  33,   49,   21,   22,   47,   26,   12,   33, 1288,    8,   21,\n",
       "          35,    8],\n",
       "       [  29,   38,   70,  194,   87,   77,  169,  160,   25,  647,   17,\n",
       "         108,    9],\n",
       "       [   6,    8,    1,    0,    6,    5,    3,    1,   14,    0, 1583,\n",
       "           6,    0],\n",
       "       [  47,   40,   43,   70,   56,   64,   69,   63,   40,   72,   24,\n",
       "        1081,   10],\n",
       "       [   0,    3,    0,    0,    1,    1,    1,    0,    1,    0,    2,\n",
       "           2, 1608]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "confusion_matrix(y_test,log_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f314754",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1_score(y_test,log_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fb53c56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.014899211218236"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,log_predictions)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd8eb2b",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0ec94bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(n_estimators=550)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "alg= GradientBoostingRegressor(n_estimators= 550, learning_rate= 0.1, max_depth= 3)\n",
    "alg.fit(x_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fff5e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_predictions = logmodel.predict(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4d5609fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1393,   34,   36,   39,   34,   15,   14,   11,   26,   27,   21,\n",
       "          46,    7],\n",
       "       [  82,  585,   60,  151,  263,   75,   55,   78,  124,   66,   42,\n",
       "          68,   17],\n",
       "       [  14,   19, 1384,   24,   20,   20,   19,   21,   18,   18,    9,\n",
       "          25,    2],\n",
       "       [  69,  119,   51,  580,  251,   76,   97,   97,   59,  159,   22,\n",
       "          77,   27],\n",
       "       [  50,  230,   59,  264,  566,   86,   54,   79,   82,  120,   28,\n",
       "          54,   23],\n",
       "       [  54,   82,   57,  106,   83,  903,   78,   88,   70,  100,   25,\n",
       "          59,   11],\n",
       "       [  40,   46,   60,  112,   68,   53,  889,  102,   34,  215,   13,\n",
       "          90,    6],\n",
       "       [  35,   38,   44,   60,   43,   61,   64, 1154,   36,  113,   11,\n",
       "          64,    7],\n",
       "       [  33,   49,   21,   22,   47,   26,   12,   33, 1288,    8,   21,\n",
       "          35,    8],\n",
       "       [  29,   38,   70,  194,   87,   77,  169,  160,   25,  647,   17,\n",
       "         108,    9],\n",
       "       [   6,    8,    1,    0,    6,    5,    3,    1,   14,    0, 1583,\n",
       "           6,    0],\n",
       "       [  47,   40,   43,   70,   56,   64,   69,   63,   40,   72,   24,\n",
       "        1081,   10],\n",
       "       [   0,    3,    0,    0,    1,    1,    1,    0,    1,    0,    2,\n",
       "           2, 1608]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "confusion_matrix(y_test,alg_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4045b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1_score(y_test,alg_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "76b0561b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.014899211218236"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,alg_predictions)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6e5f34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
